# RECOMMENDATION: create conda environment via:
#   conda create -n convqa python=3 spacy ftfy pytorch pytorch-pretrained-bert ignite tensorboardx=1.6  blas=*=mkl flask -c pytorch -c conda-forge
# NOTE: tensorboardx > 1.6 breaks ignite=0.2.0
#
# To use openai-gpt model, install spacy model for tokenization:
#   python -m spacy download en
#
# To use gpt2 model, do not install pytorch-pretrained-bert via conda, but install a certain version from history:
#   git clone https://github.com/huggingface/pytorch-pretrained-BERT.git
#   cd pytorch-pretrained-BERT
#   git reset --hard 2d6a53490dcb194b0a06edcd899a141c7ae12b01
#   pip install .
#
# Eventually, install Apex to speed up training/lower resource consumption (FP16, distributed, ...),
# e.g. "--fp16 O1" is required to train+evaluate gpt2@GPU \w 11GB memory:
#   git clone https://github.com/NVIDIA/apex
#   cd apex
#   pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
#
#########################################################################################


torch
pytorch-ignite
pytorch-pretrained-bert >= 0.6.2
tensorboardX
tensorflow  # for tensorboardX
flask # for interact endpoint
eventlet # for interact endpoint (deploy)

flask-socketio # for frontent_only (requires flink middleware, see https://github.com/ArneBinder/convqa-flink)
kafka-python # for frontent_only (requires flink middleware, see https://github.com/ArneBinder/convqa-flink)
eventlet # for frontent_only (requires flink middleware, see https://github.com/ArneBinder/convqa-flink)